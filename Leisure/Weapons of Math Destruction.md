## Weapons of Math Destruction (June 2020)

**Main Takeaways**
- Data science is all about creating models to represent solutions, but you have to be pretty careful about what you're trying to test for. Examples:
	- Creating a model for rating colleges but not including prices leads to insanely overpriced colleges, because the colleges optimize for every other factor EXCEPT price.
	- Police using ML to predict where they should be patrolling based on previous crimes, which leads to more confirmed crimes in those areas, which leads to the model placing more weight in those areas, etc... this sounds fine at first, but what if the same thing was done in affluent neighborhoods? Traffic laws, white collar crimes, etc...
	- Employment screening systems that were setup to help recruiters in the 80s, learned a model that basically threw out any resumes that didn't have "American" names
	- Political campaigning that can be super-targeted to individuals; e.g., a candidate can send different messaging to different potential voters.
	- Job application screening systems that ask psychological questions and tries to predict mental illness from them, which gets around some HIPAA / ADA considerations.
- Yes, sometimes you have to reduce a model's accuracy for fairness.
- Yes, you can remove race as a factor you're analyzing, but if you're still using something like zip codes, it's not much better. Book calls this "proxying."
- Models are good at predicting the past, but they'll never trailblaze the future.
- - This book will probably be regarding as being politically left-leaning in nature given the themes of things like empathizing with regions that have higher crime rates rather than increasing police presence.
- Biggest item: Some of these WMDs can be as bad as the most aggressive, craven capitalists in a vacuum where the ONLY thing that matters is the output you're optimizing for. "These models and ML are great for Amazon and Netflix, but not for serving out Democracy and justice."

**What can I do with this?**
- Be super careful about what any sort of data models, surveys, etc are optimizing for.
- Really like the bit about having something an Asimov's AI laws for data models like these
- Basically convinced me that open-sourcing some of these models needs to start happening. We need governance as these become more pervasive. 

**Bottom Line**
- 8/10.
- Really reinforced the idea of being responsible about what models are built for and being careful about how they're optimizing, then takes it to the next level with potential solutions around the Asimov's rules, being really cautious about where these models are being used and demanding transparency, etc.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTcxMzk1MzQyNl19
-->